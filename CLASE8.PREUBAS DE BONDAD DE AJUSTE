#PRUEBAS DE BONDAD DE AJUSTE
#EJEMPLO DEL DADO, CON CHI-CUADRADA
x<- c(43,49,56,45,66,41)
y<- c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6)
chi<-chisq.test(x,p=y)
#Ho= Datos se distribuyen uniforme discreta(1,6), H1=NO SE DEISTRIBUYEN. BUSCAMOS P-VALUE MAYOR A .05 PARA ACEPTAR H0
chi
#Chi-squared test for given probabilities
#data:  x
#X-squared = 8.96, df = 5, p-value = 0.1107
#ENTONCES ACEPTAMOS HO Y DECIMOS QUE SE DISTRIBUYE UNIFORME DISCRETA AL 95% DE CONDIANZA 

#EJEMPLO GENERADOR CUNGRENCIAL, CON KOLMOGOROV
datos<- c(.3902, .508, .9787, .888, .1024, .6723, .313605, .7254, .9409, .05277)
y<- punif(0,1)
ks.test(datos, y)
#Two-sample Kolmogorov-Smirnov test
#data:  datos and y
#D = 1, p-value = 0.1818
#alternative hypothesis: two-sided
#entonces con un 95% de confianza los datos si se distribuyen con un uniforme (0,1)

#este caso pero con la exponencial por transformada inversa
lambda<- 2
nsim<- 10^5 #numero de simulaciones
set.seed(1)
U <- runif(nsim)
X<- -log(U)/lambda # -log(1-u)/lambda ... es la formula que sacamos en la libreta
X
hist(X, breaks = 100, freq = FALSE, xlim = c(0,5), ylim = c(0,2.5))
curve(dexp(x,lambda), lwd=2, add= TRUE, col= "red")
#si ahora hacemos la prueba
ks.test(X,pexp(lambda) )
#Two-sample Kolmogorov-Smirnov test
#data:  X and pexp(lambda)
#D = 0.82058, p-value = 0.5111
#alternative hypothesis: two-sided


install.packages("goftest")
library(goftest)
datos<- c(.3902, .508, .9787, .888, .1024, .6723, .313605, .7254, .9409, .05277)
y<- punif(0,1)
#anderson mas peso a las colas
#mas estrictas
#PREUBA DE CRAMMER
cvm.test(datos,"punif",0,1)
#data:  datos
#omega2 = 0.068405, p-value = 0.7727
#bajo anderson Darling
ad.test(datos,"punif",0,1)
#data:  datos
#An = 0.51392, p-value = 0.7284
#Prueba de shapiro Wilk sirve para datos menores a 50
volumen <-c(8.39,12.14, 11.80,12.04,7.34,12.62,11.51,12.47,
            11.08,14.32,11.33,11.56,12.79,11.72,12.84,11.73,
            12.14,11.88,11.95,10.84,11.79,13.21,12.56,12.55,12.80)
install.packages("car")
require("car")
library(car)
summary(volumen)
par(mfrow=c(1,3))
mcw
hist(volumen,xlab = "Volumen de llenado",ylab ="Frecuencia", las=1,main="", col = "gray")
plot(density(volumen),xlab = "Volumen de llenado",ylab ="Frecuencia", las=1,main="")
qqPlot(volumen,xlab = "Cuantiles teoricos",ylab ="Cuantiles muestrales", las=1,main="")
#por la graficas obtenidas, se nota que no siguen una normal.
########ESTE EL CODIGO QUE ENVIO LA MAESTRA########
par(mfrow=c(1,2))
hist(volumen, xlab = "Volumen de llenado", 
     ylab = "Frecuencia", las=1, main = "", col = "gray")
plot(density(volumen), xlab = "Volumen de llenado", 
     ylab = "Densidad", las=1, main = "")
###Comparación gráfica de la función de distribución teórica de una normal
### y la distribuciòn empírica de los datos
par(mfrow=c(1,1))
xen <- seq(min(volumen), max(volumen), by=0.0001)
plot(xen, pnorm(xen, mean=par$estimate[1], sd=par$estimate[2]),
     type="l", col="red", xlab="Volumen de llenado",
     ylab="pnorm(volumen, mean, sd)")
plot(ecdf(volumen), add=TRUE)

####################################
install.packages("MASS")
require(MASS)
library("MASS")
Volumen_norm=fitdistr(volumen,"normal")
Volumen_norm
###prueba K-S
KSnorm=ks.test(volumen,"pnorm",mean=Volumen_norm$estimate[1],sd=Volumen_norm$estimate[2])
KSnorm
#D = 0.21198, p-value = 0.2112
#####Prueba AD
ADnorm=ad.test(volumen,"pnorm",mean=Volumen_norm$estimate[1],sd=Volumen_norm$estimate[2])
ADnorm
#An = 1.6222, p-value = 0.1501
#### prueba shapiro
Shnorm=shapiro.test(volumen)
Shnorm
#W = 0.81611, p-value = 0.0004272



####Ejemplo Poisson
usuarios<-c(50,42,60,39,44,54,48,44,43,50,66,62,43,50,45,43,47,46,52,55)
hist(usuarios, xlab = "Usuarios", ylab = "Frecuencia", 
     las=1, main = "", col = "gray")
require(vcd)
gf<-goodfit(usuarios, type = "poisson", method = "MinChisq")
gf$par
summary(gf)
xempp <- seq(min(usuarios), max(usuarios), by=0.0001)
plot(xempp, ppois(xempp, lambda=49.63808), type="l",
     col="red", xlab="Número de usuarios",ylab="ppois(usuarios, lambda)")
plot(ecdf(usuarios), add=TRUE)
